# compute the  probability and intensity ratios for carmont.
# uses radar fits computed by comp_radar_dist_params and GEV fits generated by comp_cpm_gev_params

import logging
import math
import numpy as np
import xarray
import matplotlib.pyplot as plt
import typing
import CPM_rainlib
import commonLib
import CPMlib
from R_python import gev_r
import scipy.stats
import pathlib

def comp_params(
        param: xarray.DataArray,
        temperature: float = 0.0,
        log10_area: typing.Optional[float] = None,
        hour: typing.Optional[float] = None,
        height: typing.Optional[float] = None
):
    if log10_area is None:
        log10_area = math.log10(150.)
    if hour is None:
        hour = 13.0
    if height is None:
        height = 100.
    result = [param.sel(parameter='shape')]  # start with shape
    param_names = dict(log10_area=log10_area, hour=hour, hour_sqr=hour ** 2, height=height,
                       CET=temperature, CET_sqr=temperature ** 2
                       )
    for k in ['location', 'scale']:
        r = param.sel(parameter=k)
        for pname, v in param_names.items():
            p = f"D{k}_{pname}"
            try:
                r = r + v * param.sel(parameter=p)
            except KeyError:
                logging.warning(f"{k} missing {p} so ignoring")
        r = r.assign_coords(parameter=k)  #  rename
        result.append(r)
    result = xarray.concat(result, 'parameter')
    return result


def xarray_samp_cov(
        da: xarray.DataArray,
        dim: str,
        param_dim: str = 'parameter',
        param_dim2: typing.Optional[str] = None
) -> xarray.DataArray:
    """ Compute the sample covariance of the data array"""

    def cov_matrix(arr):
        return np.cov(arr, rowvar=False)

    if param_dim2 is None:
        param_dim2 = param_dim + '2'
    output_core_dims = [[param_dim, param_dim2]]
    input_core_dims = [[dim, param_dim]]
    cov = xarray.apply_ufunc(cov_matrix, da, input_core_dims=input_core_dims,
                             output_core_dims=output_core_dims, vectorize=True
                             )
    cov = cov.assign_coords({param_dim2: da[param_dim].values})
    return cov


def xarray_gen_cov_samp(mean, cov, rng, nsamp):
    """ Generate  samples from the covariance matrix"""

    def gen_cov(mean, cov, rng=123456):
        return scipy.stats.multivariate_normal(mean, cov).rvs(nsamp, random_state=rng).T

    input_core_dims = [['parameter'], ['parameter', 'parameter2']]
    output_core_dims = [['parameter', 'sample', ]]
    samps = xarray.apply_ufunc(gen_cov, mean, cov, kwargs=dict(rng=rng),
                               input_core_dims=input_core_dims,
                               output_core_dims=output_core_dims, vectorize=True
                               )
    samps = samps.assign_coords(sample=np.arange(nsamp))
    return samps


def comp_scaling_cet_samps(fits: xarray.Dataset, rng, nsamp, temperature: float = 0.0):
    """
       Compute an estimate of the scaling factor for the CET relative to today.
    :param fits: fits array -- want the parameters and covariance.

    :return:cov change per frac
    :rtype:
    """
    samps = xarray_gen_cov_samp(fits.Parameters, fits.Cov, rng, nsamp)
    params = comp_params(samps, temperature=temperature)
    return params


def plot_pr_intensity(
        ax_pr, ax_intensity, params, prob_pi, intensity_pi,
        rain=None, rtn_period=None, rolling=1,
        color=None, period=None
        ):
    p_prd = gev_r.xarray_gev_sf(params, rain)  # probs of rain
    prob_ratio = p_prd / prob_pi * 100  # prob ratio as a percentage
    quant_pr = prob_ratio.quantile([0.05, 0.5, 0.95], dim='sample')
    ax_pr.fill_between(rain * rolling, quant_pr.sel(quantile=0.05), quant_pr.sel(quantile=0.95),
                       color=color, alpha=0.5
                       )
    # median estimate
    ax_pr.plot(rain * rolling, quant_pr.sel(quantile=0.5), label=period, linewidth=2, color=color)
    # print out the 5-95% range and PR values.
    # now plot the intensity ratios
    if ax_intensity is None:
        return quant_pr,None

    intensity_prd = gev_r.xarray_gev_isf(params, 1.0 / rtn_period)  # Intensity at rtn prd
    change = 100 * (intensity_prd / intensity_pi) - 100
    quant_ic = change.quantile([0.05, 0.5, 0.95], dim='sample')
    ax_intensity.fill_between(quant_ic['return_period'], quant_ic.sel(quantile=0.05), quant_ic.sel(quantile=0.95),
                              alpha=0.5, color=color
                              )
    quant_ic.sel(quantile=0.5).plot(ax=ax_intensity, x='return_period', label=period,
                                 color=color, linewidth=2
                                 )
    return quant_pr,quant_ic

def open_ds(path:pathlib.Path,dp:int=3) -> xarray.Dataset:
    # read in and then round grid_lat/grid_long coords to specified no of dps
    ds = xarray.open_dataset(path )
    # fix coords
    for c in ['grid_latitude','grid_longitude']:
        try:
            ds[c]=np.round(ds[c].astype('float32'),dp)
        except KeyError: # not coord match
            print(f'no coord {c}')
    return ds

def comp_boots_cov(boots_params:xarray.DataArray) -> xarray.DataArray:
    cv = boots_params.parameter.values
    coords=dict(parameter=cv,parameter2=cv)
    cov = []
    for roll in boots_params['rolling']:
        cov.append(
            xarray.DataArray(
                np.cov(boots_params.sel(rolling=roll),rowvar=False),
                coords=coords)
            .assign_coords(rolling=roll) 
            )

    cov = xarray.concat(cov,'rolling')
    return cov 

def b_cov(file:pathlib.Path,coords:dict,nroll:int,msk:[bool,xarray.Dataset]=True) -> xarray.DataArray:
    params = open_ds(file).Parameters.where(msk).rolling(grid_latitude=nroll, grid_longitude=nroll, center=True).mean()
    params = params.sel(**coords, method='nearest')

    cov = comp_boots_cov(params)
    return cov


my_logger = CPM_rainlib.logger
commonLib.init_log(my_logger, level='INFO')
npts=5 # Number of x/y points to average over. 
if npts == 5: # default output file 
    fig_name = 'intens_prob_ratios'
else:
    fig_name = f'intens_prob_ratios_{npts}'
ht = open_ds(CPM_rainlib.dataDir/'cpm_topog_fix_c2.nc').ht.sel(CPMlib.carmont_rgn)
# fix coords. They differ by small fp values...
msk = ht > 0
# read in the radar data
radar_fit_dir = CPMlib.radar_dir / 'radar_rgn_fit'
#
carmont = CPMlib.carmont_drain_OSGB.copy()
carmont.update(time='2020-08')
radar_fit = dict()
radar_rain = dict()

for path in radar_fit_dir.glob('*_fit.nc'):
    name = path.stem.replace('_fit', '')
    radar_fit[name] = xarray.load_dataset(path)
# read in the summary data and get the actual rain values
for name in radar_fit.keys():
    summary_path = CPMlib.radar_dir / 'summary' / f'summary_2008_{name}.nc'
    radar_rain[name] = xarray.open_dataset(summary_path).Radar_rain_Max.sel(**carmont, method='nearest').load()
    mx_time = xarray.open_dataset(summary_path).Radar_rain_MaxTime.sel(**carmont, method='nearest').load()
    my_logger.debug(f"Max Time for {name} radar data is {mx_time.dt.strftime('%Y-%m-%d %H:%M').values}")

my_logger.debug(f"Loaded radar data")

## get in the model fits and work out ratios for today and PI
fit_dir = CPM_rainlib.dataDir / 'CPM_scotland_filter' / "fits"
fit_file = fit_dir / 'carmont_rgn_fit_CET.nc'
fits = open_ds(fit_file).where(msk) 
cpm_gev_params = fits.rolling(grid_latitude=npts, grid_longitude=npts, center=True,min_periods=1).mean()
cpm_gev_params = cpm_gev_params.sel(**CPMlib.carmont_drain, method='nearest')  # get the data for the carmont drain
count = float(fits.Parameters.isel(rolling=0,parameter=0).\
    rolling(grid_latitude=npts, grid_longitude=npts, center=True,min_periods=1).count().\
    sel(**CPMlib.carmont_drain, method='nearest'))
cpm_gev_params['Cov'] = cpm_gev_params['Cov'] / count  # average over count points so covariance down by a factor of count
# get inthe bootstrap data and compute covariance


boots_fit_file = fit_dir/f'carmont_rgn_fit_boot_CET.nc'
boots_cov = b_cov(boots_fit_file,CPMlib.carmont_drain,5,msk=msk)
cpm_gev_params['Cov_boots']=boots_cov
 
# get in the raw data
raw_fit_dir = CPM_rainlib.dataDir / 'CPM_scotland' / "fits"
raw_fit_file = raw_fit_dir / 'carmont_fit_raw_CET.nc'
raw_cpm_gev_params = open_ds(raw_fit_file).where(msk).rolling(grid_latitude=5, grid_longitude=5, center=True).mean()
raw_cpm_gev_params = raw_cpm_gev_params.sel(**CPMlib.carmont_drain, method='nearest'
                                            )  # get the data for the carmont drain
raw_cpm_gev_params['Cov'] = raw_cpm_gev_params[
                                'Cov'] / 25.  # average over 25 points so covariance down by a factor of 25.
boots_fit_file = raw_fit_dir/f'carmont_fit_raw_boot_CET.nc'
boots_cov = b_cov(boots_fit_file,CPMlib.carmont_drain,5,msk=msk)
raw_cpm_gev_params['Cov_boots']=boots_cov
my_logger.debug(f"Loaded CPM data")
obs_cet = commonLib.read_cet()  # read in the obs CET
obs_cet_jja = obs_cet.where(obs_cet.time.dt.season == 'JJA', drop=True)
t_today = float(obs_cet_jja.sel(**CPMlib.today_sel).mean())
t_PI = float(obs_cet_jja.sel(**CPMlib.PI_sel).mean())
t_1980s = float(obs_cet_jja.sel(time=slice('1980-01-01', '1989-12-31')).mean())
delta = t_PI - t_today
temp_p2k = scipy.stats.norm(loc=2 * 0.94 + t_PI, scale=2 * 0.03)
# how much more summer-time CET is at +2K warming Values provided by Prof. Ed Hawkins (Reading) -- as used in Tett et al, 2023.
nsamp = 1000
temp_p2k_samp = xarray.DataArray(temp_p2k.rvs(nsamp, random_state=123456), dims='sample')
params_cpm_samp = xarray_gen_cov_samp(cpm_gev_params.Parameters, cpm_gev_params.Cov_boots, 123456, nsamp)
today_str = CPMlib.today_sel['time'].start + '-' + CPMlib.today_sel['time'].stop[-2:]
params_cpm = {key: comp_params(params_cpm_samp, temperature=t - t_PI) for
              key, t in zip([today_str, 'PI', '+2C', '1980-89'], [t_today, t_PI, temp_p2k_samp, t_1980s])}
raw_params_cpm_samp = xarray_gen_cov_samp(raw_cpm_gev_params.Parameters, raw_cpm_gev_params.Cov_boots, 123456, nsamp)
raw_params_cpm = {key: comp_params(raw_params_cpm_samp, temperature=t - t_PI) for
                  key, t in zip([today_str, 'PI', '+2C', '1980-89'], [t_today, t_PI, temp_p2k_samp, t_1980s])}
# compute scalings for radar dist to take it to specified temperature.
ratio = dict()
raw_ratio = dict()
for key, params in params_cpm.items():
    ratio[key] = params / params_cpm[today_str]
    raw_ratio[key] = raw_params_cpm[key] / raw_params_cpm[today_str]

my_logger.debug(f"Generated samples")

radar_today = {key: xarray_gen_cov_samp(fit.Parameters, fit.Cov, 123456, nsamp) for key, fit in radar_fit.items()}
my_logger.debug(f"Generated radar samples")

## now plot the data
fig, axs = plt.subplots(num=fig_name, clear=True, nrows=2, ncols=3, layout='constrained', figsize=(8, 6),
                        sharey='col', sharex='col'
                        )
fig.get_layout_engine().set(rect=[0.05, 0.0, 0.95, 1.0])
#for ax,(name,rolling) in zip(axis.flat,itertools.product(['1km','5km'],[1,4])):
rain = np.geomspace(2, 80)
rtn_period = np.geomspace(5, 200)
label = commonLib.plotLabel()
i_pi = {key: gev_r.xarray_gev_isf(radar_fit * ratio['PI'], 1.0 / rtn_period) for key, radar_fit in radar_today.items()}
p_pi = {key: gev_r.xarray_gev_sf(radar_fit * ratio['PI'], rain) for key, radar_fit in radar_today.items()}
raw_i_pi = {key: gev_r.xarray_gev_isf(radar_fit * raw_ratio['PI'], 1.0 / rtn_period) for key, radar_fit in
            radar_today.items()}
raw_p_pi = {key: gev_r.xarray_gev_sf(radar_fit * raw_ratio['PI'], rain) for key, radar_fit in radar_today.items()}
names = ['1km', '5km']
for axis, rolling in zip(axs, [1, 4]):
    pos = axis[0].get_position()
    y = (pos.ymax + pos.ymin) / 2
    x = 0.02
    fig.text(x, y, f'Rx{rolling:d}h',
             ha='left', va='center', rotation=90, fontsize=10
             )
    for index, name in enumerate(names):  # loop over different radars

        ax_pr = axis[index]
        try:
            ax_intensity = axis[index + len(names)]
        except IndexError:
            ax_intensity = None

        radar_fit = radar_today[name].sel(rolling=rolling)
        prob_pi = p_pi[name].sel(rolling=rolling)
        intensity_pi = i_pi[name].sel(rolling=rolling)
        raw_prob_pi = raw_p_pi[name].sel(rolling=rolling)
        raw_intensity_pi = raw_i_pi[name].sel(rolling=rolling)
        rain_2020 = float(radar_rain[name].sel(rolling=rolling))
        for color, period, temp in zip(['cornflowerblue', 'blue', 'red'],
                                       ['1980-89', today_str, '+2C'], [t_1980s, t_today, temp_p2k_samp]
                                       ):

            params = ratio[period].sel(rolling=rolling) * radar_fit
            q_pr,q_ic = plot_pr_intensity(ax_pr, ax_intensity, params, prob_pi, intensity_pi,
                              rain=rain, rtn_period=rtn_period, rolling=rolling, color=color, period=period
                              )
            pr = q_pr.interp(dict(threshold=rain_2020))
            prt_pr = " ".join([f"{float(pr[i]):3.0f}" for i in range(3)])
            print(f"PRs for Rx{rolling:d}h {name} {period}  are ", prt_pr, " %")
            if ax_intensity:  # got an intensity axis so plot CC
                if isinstance(temp, xarray.DataArray):
                    cc = xarray.DataArray(CPMlib.cc_dist.rvs(nsamp), dims=['sample']) * (temp - t_PI)
                    cc = cc.quantile([0.05, 0.5, 0.95]).values
                else:
                    cc = CPMlib.cc_dist.isf([0.05, 0.5, 0.95]) * (temp - t_PI)

                ax_intensity.axhspan(cc[0], cc[2], color=color, alpha=0.5)
                ax_intensity.axhline(cc[1], linestyle='dashed', color=color)
        # add on the +2K raw values
        period = '+2C'
        params_raw = raw_ratio[period].sel(rolling=rolling) * radar_fit
        plot_pr_intensity(ax_pr, ax_intensity, params_raw, raw_prob_pi, raw_intensity_pi,
                          rain=rain, rtn_period=rtn_period, rolling=rolling, color='brown', period=period + ' Raw'
                          )
        # actual rain values
        ax_pr.axvline(rain_2020 * rolling, color='black', linewidth=2)
        if ax_intensity:
            # compute the return periods for event today and plot them as median and 5-95% uncertainty.
            rp = 1.0 / (gev_r.xarray_gev_sf(radar_fit, rain_2020))
            rp_quant = rp.quantile([0.05, 0.5, 0.95], dim='sample')
            ic = q_ic.interp(dict(pvalues=1.0/rp_quant.sel(quantile=0.5).values)).values
            prt_ic = " ".join([f"{float(ic[i][0]):3.1f}" for i in range(3)])
            prt_cc = " ".join([f"{float(cc[i]):3.1f}" for i in range(3)])
            print(f"ICs for Rx{rolling:d}h {name} {period}  are ",prt_ic," % cc=",prt_cc)
            ax_intensity.axvspan(float(rp_quant.sel(quantile=0.05)), float(rp_quant.sel(quantile=0.95)), color='grey',
                                 alpha=0.5
                                 )
            ax_intensity.axvline(rp_quant.sel(quantile=0.5), linestyle='solid', color='black', linewidth=2)
        # decorate the axis
        ax_pr.set_title(f'{name} Probability Ratio')
        ax_pr.set_xlabel('Accumulated Rain (mm)')
        ax_pr.set_ylabel('Probability Ratio (%)')
        ax_pr.set_xlim(5, 80)
        ax_pr.set_ylim(100, 170)
        if ax_intensity is not None:
            ax_intensity.set_title(f'{name} Intensity Increase')
            ax_intensity.set_xlabel('Return Period (summers)')
            ax_intensity.set_ylabel('Intensity Change (%)')
            ax_intensity.set_xscale('log')

            xticks = [5, 10, 20, 50, 100, 200]
            ax_intensity.set_xticks(xticks)
            ax_intensity.set_xticklabels([str(tick) for tick in xticks])
for a in axs.flat:
    label.plot(a)
axs[1][0].legend(ncol=2, fontsize='small', borderpad=0., labelspacing=0.2, handletextpad=0.25, columnspacing=0.25)
fig.show()
commonLib.saveFig(fig)
